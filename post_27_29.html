<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Avinash Sen - Master's Project Blog</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/clean-blog.min.css" rel="stylesheet">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="about.html">Avinash Sen</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="about.html">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="contact.html">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Header -->
    <header class="masthead" style="background-image: url('img/week_27_29.jpg')">
      <div class="overlay"></div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <div class="post-heading">
              <h1>Week 27-29 </h1>
              <h2 class="subheading">DOPE code Training and Testing. Detection by 3D bounding box and Pose Output of Demo object.</h2>
              <span class="meta">Posted by
                <a href="about.html">Avinash Sen</a>
                on April 12, 2020</span>
            </div>
          </div>
        </div>
      </div>
    </header>

    <!-- Post Content -->
    <article>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <font size="6"><b>DOPE code Training and Testing for Demo object</b></font>
            <p>
              This network was implemented using PyTorch v0.4. The VGG-19 feature extractions were taken from publicly available trained weights in torchvision open models.
              The networks were trained for 60 epochs with a batchsize of 16 for this Demo object. Adam was used as the optimizer with learning rate set at 0.0001.
              The system was trained on an Dell Precision 7820 workstation (containing NVIDIA P4000 16GB GPU), and testing used same.
            </p>
            <p>For more, Download the Dataset from <a href="https://research.nvidia.com/publication/2018-06_Falling-Things">https://research.nvidia.com/publication/2018-06_Falling-Things</a> and
              train the objects by <a href="https://github.com/NVlabs/Deep_Object_Pose/blob/master/scripts/train.py">https://github.com/NVlabs/Deep_Object_Pose/blob/master/scripts/train.py</a> to get respective weights.
            </p>
            <center>
              <p><img class="img-fluid" src="img/training.jpg" alt=""></p>
            </center>
            <p><b>Experimental Setup for Testing the Demo object:</b></p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/7gsZfrnAFLY?autoplay=1&loop=1&playlist=7gsZfrnAFLY">
                </iframe>
              </center>
            </p>
                        
            <font size="6"><b>Detection by 3D bounding box and Pose Output of Demo object</b></font>
            <p>
              After the network has processed an image, it is necessary to extract the individual objects from the belief maps. 
            </p>
            
            <p><b>Detection of the Demo Object:</b>
              This approach relies on a simple postprocessing step that searches for local peaks in the belief maps above a threshold,
              followed by a greedy assignment algorithm that associates projected vertices to detected centroids. For each vertex,
              this latter step compares the vector ﬁeld evaluated at the vertex with the direction from the vertex to each centroid,
              assigning the vertex to the closest centroid within some angular threshold of the vector. 
            </p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/kFdxqJA0BTg?autoplay=1&loop=1&playlist=kFdxqJA0BTg">
                </iframe>
              </center>
            </p>
            <p><b>Pose Output of the Demo object:</b>
              Once the vertices of each object instance have been determined, a PnP algorithm is used to retrieve the pose of the object.
              This step uses the detected projected vertices of the bounding box, the camera intrinsics,
              and the object dimensions to recover the ﬁnal translation and rotation of the object with respect to the camera.
              All detected projected vertices are used, as long as at least the minimum number (four) are detected.
            </p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/cB5miHZ5tPc?autoplay=1&loop=1&playlist=cB5miHZ5tPc">
                </iframe>
              </center>
            </p>
            <p>
              The network employs multiple stages to reﬁne ambiguous estimates of the 2D locations of projected vertices of each object’s 3D bounding cuboid.
              These points are then used to predict the ﬁnal pose using PnP, assuming known camera intrinsics and object dimensions.
            </p>

            <!-- Pager -->
            <div class="clearfix">
              <a class="btn btn-primary float-left" href="post_25_26.html">&larr;Previous Week </a>
              <a class="btn btn-primary float-right" href="post_30.html">Next Week &rarr;</a>
            </div>            
          
          </div>
        </div>
      </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <ul class="list-inline text-center">
              <!-- <li class="list-inline-item">
                <a href="#">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li> -->
              <li class="list-inline-item">
                <a href="https://www.facebook.com/avinashsen707">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/avinashsen707">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
            </ul>
            <p class="copyright text-muted">Copyright 2020 &copy; avinashsen707.github.io</p>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/clean-blog.min.js"></script>

  </body>

</html>
