<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Avinash Sen - Master Research Project Blog</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/clean-blog.min.css" rel="stylesheet">
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="about.html">Avinash Sen</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="about.html">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="contact.html">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Header -->
    <header class="masthead" style="background-image: url('img/week_27_29.jpg')">
      <div class="overlay"></div>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <div class="post-heading">
              <h1>Week 46-48 </h1>
              <h2 class="subheading">System Integration, Experiments and Results.</h2>
              <span class="meta">Posted by
                <a href="about.html">Avinash Sen</a>
                on June 21, 2020</span>
            </div>
          </div>
        </div>
      </div>
    </header>

    <!-- Post Content -->
    <article>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <font size="6"><b>Implementation in ROS Framework.</b></font>
            <p>
              With the complete hardware calibrated, and having the objects in the workspace successfully detected, it is now possible to develop the precise bin-picking vision system.
              The description of the steps required for the development and Evaluation of the entire process is presented next; This section describes the purpose of each node, explains the connection among them all and how they communicate with each other and through each topics.
              ROS (ROBOT OPERATING SYSTEM) : It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behaviour across a wide variety of robotic platforms.

              <p>
                ROS contains diﬀerent distributions which are a versioned set of ROS packages. The one used in this project is the ROS Kinetic Kame.
                We attached an Intel Realsense D435i depth camera to the 6th link of a Aubo i5 robot.
                The workstation and the robot connected via Ethernet cable for fast communication and the rest camera was connected by USB Type–C in the drive.
              </p>
            
              Download : <a href="https://github.com/avinashsen707/AUBOi5-D435-ROS-DOPE">Link____</a>
            </p>

            <p><b>Experimental Setup :</b></p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/7gsZfrnAFLY?autoplay=1&loop=1&playlist=7gsZfrnAFLY">
                </iframe>
              </center>
            </p>
            
            <p><b>Running ROS master, camera node, DOPE node and rviz node:</b></p>
            <p>
              1. Start ROS master :
              <div style="background: #f0f0f0; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">cd ~/catkin_ws | source devel/setup.bash |  roscore</pre></div>
              2.Start camera node (or start your own camera node)
              <div style="background: #f0f0f0; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">roslaunch realsense2_camera rs_rgbd.launch  # Publishes RGB images to `/camera/color/image_raw`</pre></div>
              3. Start DOPE node
              <div style="background: #f0f0f0; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">roslaunch dope dope.launch [config:=/path/to/my_config.yaml]</pre></div>
              4. Start rviz node
              <div style="background: #f0f0f0; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">rosrun rviz rviz</pre></div>
              To debug in RViz, run rviz, then add one or more of the following displays:
              <div style="background: #f0f0f0; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;">
                <pre style="margin: 0; line-height: 125%">
                  Add > Image to view the raw RGB image or the image with cuboids overlaid |
                  Add > Pose to view the object coordinate frame in 3D. | 
                  Add > MarkerArray to view the cuboids, meshes etc. in 3D. | 
                  Add > Camera to view the RGB Image with the poses and markers from above.
                </pre>
              </div>
            </p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/QKuz-MHvrPk?autoplay=1&loop=1&playlist=QKuz-MHvrPk">
                </iframe>
              </center>
            </p>

            <font size="6"><b>Experiments and Results</b></font>
            <p>
              After the network has processed an image, it is necessary to extract the individual objects from the belief maps.
              In order to evaluate and demonstrate the performance of the developed bin-picking vision system, several tests were taken and a demonstration was held to present the versatility of the system.
              For this particular project, this sort of assessment could be done by evaluating the number of successes in the identiﬁcation and pose estimation of a demo object.

              For better results, we took the object cracker, almost random, at 4 various areas on a table in front of the robot, at 3 various orientations for each of the 4 places.
            </p>
            
            <p>
              <p><b>Detection</b></p>
              This approach relies on a simple postprocessing step that searches for local peaks in the belief maps above a threshold,
              followed by a greedy assignment algorithm that associates projected vertices to detected centroids. For each vertex,
              this latter step compares the vector ﬁeld evaluated at the vertex with the direction from the vertex to each centroid,
              assigning the vertex to the closest centroid within some angular threshold of the vector. 
            </p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/kFdxqJA0BTg?autoplay=1&loop=1&playlist=kFdxqJA0BTg">
                </iframe>
              </center>
            </p>
            <p>
              <p><b>Pose Output</b></p>
              Once the vertices of each object instance have been determined, a PnP algorithm is used to retrieve the pose of the object.
              This step uses the detected projected vertices of the bounding box, the camera intrinsics, and the object dimensions to recover the ﬁnal translation and rotation of the object with respect to the camera.
              All detected projected vertices are used, as long as at least the minimum number (four) are detected.
            </p>
            <p>
              <center>
                <iframe width="640" height="360"
                 src="https://www.youtube.com/embed/cB5miHZ5tPc?autoplay=1&loop=1&playlist=cB5miHZ5tPc">
                </iframe>
              </center>
            </p>
            <p>
              The network employs multiple stages to reﬁne ambiguous estimates of the 2D locations of projected vertices of each object’s 3D bounding cuboid.
              These points are then used to predict the ﬁnal pose using PnP, assuming known camera intrinsics and object dimensions.

              The robot was programed to go to distance before grasp coordinates above the object. The prototype object detected and pose estimated successfully in various orientations.
              We rotated the objects 6-DOF and the object detection was quite successful.
            </p>
                     
            <!-- Pager -->
            <div class="clearfix">
              <a class="btn btn-primary float-left" href="post_39_45.html">&larr;Previous Week </a>
              <a class="btn btn-primary float-right" href="post_49_50.html">Next Week &rarr;</a>
            </div>

          </div>
        </div>
      </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-md-10 mx-auto">
            <ul class="list-inline text-center">
              <!-- <li class="list-inline-item">
                <a href="#">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li> -->
              <li class="list-inline-item">
                <a href="https://www.facebook.com/avinashsen707">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/avinashsen707">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
            </ul>
            <p class="copyright text-muted">Copyright 2020 &copy; avinashsen707.github.io</p>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/clean-blog.min.js"></script>

  </body>

</html>
